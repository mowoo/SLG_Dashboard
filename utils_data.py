import pandas as pd
import os
import re
import datetime
import streamlit as st

# --- é…ç½® ---
DATA_FOLDER = "ç›Ÿæˆ°è³‡æ–™åº«"
EXCLUDE_GROUPS = ['å°è™Ÿ', 'æœªåˆ†çµ„']
RADAR_CONFIG = {
    'slave':  {'desc': 'ğŸ‘®â€â™‚ï¸ æŠ“åœ°å¥´', 'merit_op': 'å°æ–¼ <=', 'merit_val': 10000, 'power_op': 'å¤§æ–¼ >=', 'power_val': 25000, 'eff_op': 'å°æ–¼ <=', 'eff_val': 2.0},
    'elite':  {'desc': 'âš”ï¸ æ‰¾æˆ°ç¥', 'merit_op': 'å¤§æ–¼ >=', 'merit_val': 100000, 'power_op': 'å¤§æ–¼ >=', 'power_val': 0, 'eff_op': 'å¤§æ–¼ >=', 'eff_val': 10.0},
    'newbie': {'desc': 'ğŸ‘¶ æ‰¾èŒæ–°', 'merit_op': 'å°æ–¼ <=', 'merit_val': 5000, 'power_op': 'å°æ–¼ <=', 'power_val': 10000, 'eff_op': 'å¤§æ–¼ >=', 'eff_val': 0.0},
    'reset':  {'desc': 'ğŸ”„ é‡ç½®', 'merit_op': 'å¤§æ–¼ >=', 'merit_val': 0, 'power_op': 'å¤§æ–¼ >=', 'power_val': 0, 'eff_op': 'å¤§æ–¼ >=', 'eff_val': 0.0}
}

# --- IO å‡½æ•¸ ---
def save_uploaded_file(uploaded_file):
    if not os.path.exists(DATA_FOLDER): os.makedirs(DATA_FOLDER)
    try:
        with open(os.path.join(DATA_FOLDER, uploaded_file.name), "wb") as f: f.write(uploaded_file.getbuffer())
        return True
    except: return False

@st.cache_data(ttl=300)
def load_data_from_folder():
    if not os.path.exists(DATA_FOLDER): return pd.DataFrame()
    all_data = []
    files = [f for f in os.listdir(DATA_FOLDER) if f.endswith('.csv')]
    
    for filename in files:
        try:
            df = pd.read_csv(os.path.join(DATA_FOLDER, filename))
            
            # Extract timestamp from filename
            # Format: åŒç›Ÿçµ±è¨ˆYYYYå¹´MMæœˆDDæ—¥HHæ—¶mmåˆ†SSç§’.csv
            match = re.search(r'(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥(\d{2})æ—¶(\d{2})åˆ†(\d{2})ç§’', filename)
            if match:
                dt_str = f"{match.group(1)}-{match.group(2)}-{match.group(3)} {match.group(4)}:{match.group(5)}:{match.group(6)}"
                df['ç´€éŒ„æ™‚é–“'] = pd.to_datetime(dt_str)
            else:
                if 'ç´€éŒ„æ™‚é–“' not in df.columns:
                     print(f"Warning: Could not extract timestamp from {filename} and column missing.")
                     continue

            all_data.append(df)
        except Exception as e:
            print(f"Error loading {filename}: {e}")
        
    if not all_data: return pd.DataFrame()
    
    full_df = pd.concat(all_data, ignore_index=True)
    
    if 'ç´€éŒ„æ™‚é–“' in full_df.columns:
        full_df = full_df.sort_values('ç´€éŒ„æ™‚é–“')
        
    required_cols = ['å‹¢åŠ›å€¼', 'æˆ°åŠŸç¸½é‡', 'åˆ†çµ„']
    missing_cols = [col for col in required_cols if col not in full_df.columns]
    if missing_cols:
        st.error(f"è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}ï¼Œè«‹æª¢æŸ¥ä¸Šå‚³çš„ CSV æª”æ¡ˆæ ¼å¼ã€‚")
        return pd.DataFrame()
        
    full_df['å‹¢åŠ›å€¼'] = full_df['å‹¢åŠ›å€¼'].replace(0, 1)
    full_df['æˆ°åŠŸæ•ˆç‡'] = (full_df['æˆ°åŠŸç¸½é‡'] / full_df['å‹¢åŠ›å€¼']).round(2)
    full_df = full_df[~full_df['åˆ†çµ„'].isin(EXCLUDE_GROUPS)]
    return full_df

# --- è¨ˆç®—å‡½æ•¸ ---
@st.cache_data(ttl=300)
def calculate_daily_velocity(df, group_col=None):
    df = df.copy()
    df['date_only'] = df['ç´€éŒ„æ™‚é–“'].dt.date
    daily_snapshots = df.groupby('date_only')['ç´€éŒ„æ™‚é–“'].max().reset_index()
    df_daily = pd.merge(df, daily_snapshots, on=['date_only', 'ç´€éŒ„æ™‚é–“'], how='inner')
    
    if group_col:
        agged = df_daily.groupby(['ç´€éŒ„æ™‚é–“', group_col])[['æˆ°åŠŸç¸½é‡', 'å‹¢åŠ›å€¼']].sum().reset_index()
        agged = agged.sort_values([group_col, 'ç´€éŒ„æ™‚é–“'])
        agged['time_diff'] = agged.groupby(group_col)['ç´€éŒ„æ™‚é–“'].diff().dt.total_seconds() / 86400
        agged['merit_diff'] = agged.groupby(group_col)['æˆ°åŠŸç¸½é‡'].diff()
        agged['power_diff'] = agged.groupby(group_col)['å‹¢åŠ›å€¼'].diff()
    else:
        agged = df_daily.groupby('ç´€éŒ„æ™‚é–“')[['æˆ°åŠŸç¸½é‡', 'å‹¢åŠ›å€¼']].sum().reset_index()
        agged = agged.sort_values('ç´€éŒ„æ™‚é–“')
        agged['time_diff'] = agged['ç´€éŒ„æ™‚é–“'].diff().dt.total_seconds() / 86400
        agged['merit_diff'] = agged['æˆ°åŠŸç¸½é‡'].diff()
        agged['power_diff'] = agged['å‹¢åŠ›å€¼'].diff()
        
    agged['daily_merit_growth'] = (agged['merit_diff'] / agged['time_diff']).fillna(0)
    agged['daily_power_growth'] = (agged['power_diff'] / agged['time_diff']).fillna(0)
    return agged

def get_individual_global_max(raw_df):
    temp_df = calculate_daily_velocity(raw_df, group_col='æˆå“¡')
    g_max_m = temp_df['daily_merit_growth'].max()
    g_max_p = temp_df['daily_power_growth'].max()
    g_min_p = temp_df['daily_power_growth'].min()
    return g_max_m, g_max_p, g_min_p